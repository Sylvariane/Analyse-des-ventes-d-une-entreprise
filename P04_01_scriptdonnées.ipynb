{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "P04_01_scriptdonnées.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HRhETLIO3zmu",
        "cKwGHqAK3znT",
        "_oP_PW1e3znq",
        "EeuqKbQZ3zn0",
        "kN4frweE3zoE",
        "Ma8KEfPb3zoO",
        "viTkjAdK3zoW",
        "N4MpSEqA3zol",
        "OXBvz2Rh3zoq",
        "Xg1rUzAc3zoy",
        "AHRJiMpA3zo5",
        "6D5NdEdr3zo_"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sylvariane/Analyse-vente/blob/master/P04_01_scriptdonn%C3%A9es.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkqI8f6U3zl3",
        "colab_type": "text"
      },
      "source": [
        "# Script de nettoyage des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7ikrXIj8FRE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "adf3c333-f5b1-46e9-d209-e5e85ddfd71f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oac7y2Mh3zl6",
        "colab_type": "text"
      },
      "source": [
        "## 1. Téléchargements des modules et des fichiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJLxxyfA3zl8",
        "colab_type": "text"
      },
      "source": [
        "Pour le nettoyage des données, on utilise trois librairies dont deux spécifiques aux Data Sciences : Pandas et NumPy. On importe aussi la librairie datetime pour modifier les dates en un objet spécifique 'Date'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8HX69rp3zl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v13wHLhh3zmL",
        "colab_type": "text"
      },
      "source": [
        "Une fois les différents modules importés, on charge les fichiers bruts nécessaires à notre analyse. On dispose d'un jeu de données composé de trois fichiers : un fichier contenant les ventes, nommé transactions, mais qui sera renommé sells ; un fichier contenant les informations concernant les clients nommé customers puis renommé custom et un fichier contenant les informations les produits vendus se nommant products et qui sera renommé prod pour le reste de l'analyse."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3QmtDGt3zmM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "0d29dc13-66f5-48cb-b561-713cf5b84356"
      },
      "source": [
        "sells = pd.read_csv('/content/drive/My Drive/Formation Data Analyst/Livrables/P4_guillot_cecile/sources/transactions.csv')\n",
        "custom = pd.read_csv('/content/drive/My Drive/Formation Data Analyst/Livrables/P4_guillot_cecile/sources/customers.csv')\n",
        "prod = pd.read_csv('/content/drive/My Drive/Formation Data Analyst/Livrables/P4_guillot_cecile/sources/products.csv')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-24e671a1dc6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msells\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Formation Data Analyst/Livrables/sources/transactions.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcustom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Formation Data Analyst/Livrables/sources/customers.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Formation Data Analyst/Livrables/sources/products.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /content/drive/My Drive/Formation Data Analyst/Livrables/sources/transactions.csv does not exist: '/content/drive/My Drive/Formation Data Analyst/Livrables/sources/transactions.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84yzgijR3zmU",
        "colab_type": "text"
      },
      "source": [
        "Dans un premier temps, les fichiers seront nettoyés un par un puis ensuite, ils seront croisés. Dans une dernière partie, les fichiers crées seront enregistrés pour être analysé. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA88WFJY3zmW",
        "colab_type": "text"
      },
      "source": [
        "## 2. Nettoyage des données du fichier des transactions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wzi72PPJ3zmX",
        "colab_type": "text"
      },
      "source": [
        "On commence par afficher les premières lignes du DataFrame pour voir sa composition. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjVgYsJY3zmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(sells.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu5qSV2d3zmh",
        "colab_type": "text"
      },
      "source": [
        "Le DataFrame des ventes contient quatre colonnes : l'identifiant des produits, la date de la transaction, le numéro de la session et l'identifiant du client acheteur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KNAfomU3zmi",
        "colab_type": "text"
      },
      "source": [
        "### 2.1. Analyse des données manquantes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEXPGwFM3zmj",
        "colab_type": "text"
      },
      "source": [
        "On affiche ensuite les données manquantes pouvant s'être introduite dans le fichier. Elles sont notées par le symbole NaN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVmg2Dba3zml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sells.isna().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX_dannz3zms",
        "colab_type": "text"
      },
      "source": [
        "Le fichier contenant les informations sur les transactions ne présentent pas de données manquantes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRhETLIO3zmu",
        "colab_type": "text"
      },
      "source": [
        "### 2.2. Analyse des données dupliquées"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72dca_tn3zmv",
        "colab_type": "text"
      },
      "source": [
        "On crée une variable qui contient les données dupliquées. Ensuite, on affiche les données dupliquées du DataFrame. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwYyWIgo3zmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duplicated_sells = sells.duplicated()\n",
        "sells[duplicated_sells]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeAkPWcU3zm1",
        "colab_type": "text"
      },
      "source": [
        "On observe la présence de 126 lignes correspondant à des sessions de tests. Il faudra donc les supprimer du fichier des transactions mais aussi des autres fichiers. Il faudra enlever le produit ayant un id_prod correspond à T_0 dans le fichier des produits et les clients dont le client_id correspond à ct_0 et ct_1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVT8oc9Z3zm2",
        "colab_type": "text"
      },
      "source": [
        "On supprime donc les valeurs dupliquées correspond aux sessions test du 1er mars."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL_5Twjs3zm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('mode.chained_assignment', None)\n",
        "sells = sells.drop_duplicates()\n",
        "sells[duplicated_sells]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqhQNsat3zm-",
        "colab_type": "text"
      },
      "source": [
        "Les valeurs dupliquées sont donc supprimées mais il reste encore des données de session test avec l'identifiant s_0. On va donc supprimer ces valeurs pour pouvoir faire son analyse. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JguN5VkP3zm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sells.loc[sells['session_id'] == 's_0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AijILIjD3znE",
        "colab_type": "text"
      },
      "source": [
        "Pour supprimer toutes les données issues des tests, on supprime toutes les sessions dont l'identifiant session vaut 's_0'. On crée donc une liste contenant les index des lignes avec l'identifiant de session s_0 puis on supprime les lignes associées à l'aide de la méthode .drop()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMXZmnum3znG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_s_0 = sells[sells['session_id'] == 's_0'].index.values\n",
        "sells.drop(index_s_0, 0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TodOxifJ3znM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sells.loc[sells['session_id'] == 's_0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKwGHqAK3znT",
        "colab_type": "text"
      },
      "source": [
        "### 2.3. Analyse des types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDASH2kl3znV",
        "colab_type": "text"
      },
      "source": [
        "Une fois ces différents nettoyages effectués, on s'intéresse aux types de données contenus dans le fichier des transactions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My8ksUX63znX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(sells.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUGs2VkM3zna",
        "colab_type": "text"
      },
      "source": [
        "On remarque que toutes les variables sont considérées comme des objets. On peut transformer la variable 'date' en type 'datetime'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOiify0_3znb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sells['date'] = pd.to_datetime(sells['date'])\n",
        "print(sells.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBX-1jxv3znh",
        "colab_type": "text"
      },
      "source": [
        "Une fois cette transformation faite, il est plus simple d'organiser les données par ordre chronologique. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsfFFfC53znk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sells = sells.sort_values('date')\n",
        "sells = sells.set_index('date')\n",
        "print(sells.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oP_PW1e3znq",
        "colab_type": "text"
      },
      "source": [
        "## 3. Nettoyage des données des produits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRgm5s1J3znq",
        "colab_type": "text"
      },
      "source": [
        "Comme pour le fichier des transactions, on affiche les premiers lignes du fichier des produits pour pouvoir se familiariser avec ce fichier et voir sa composition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C7mgGbC3znr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(prod.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHQnjN7p3zny",
        "colab_type": "text"
      },
      "source": [
        "Ce dataframe est composé de trois colonnes contenant les identifiants des produits, les prix des produits et la catégorie d'appartenance de chacun des produits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeuqKbQZ3zn0",
        "colab_type": "text"
      },
      "source": [
        "### 3.1. Analyse des types dans le fichier des produits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_heB8rZ3zn1",
        "colab_type": "text"
      },
      "source": [
        "On regarde le détail des types de données contenues dans le dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "118SKCOD3zn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prod.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF2SvhtR3zn6",
        "colab_type": "text"
      },
      "source": [
        "Il serait plus intéressant de modifier le type de la colonne 'categ' en une valeur catégorielle. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kB05uZl3zn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prod['categ'] = prod['categ'].astype('category')\n",
        "prod.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laPRiUqh3zoA",
        "colab_type": "text"
      },
      "source": [
        "On peut ainsi classer les produits par ordre de catégorie. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5Km2htc3zoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prod = prod.sort_values('categ')\n",
        "print(prod)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN4frweE3zoE",
        "colab_type": "text"
      },
      "source": [
        "### 3.2. Analyse des valeurs manquantes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xpx6bkpZ3zoF",
        "colab_type": "text"
      },
      "source": [
        "Après la modification des types, on s'intéresse à la présence de données manquantes qui vont prendre la forme de NaN dans notre DataFrame. Pour identifier ces valeurs, on utiliser la fonction isna() associée à any()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAJgeNfF3zoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prod.isna().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i_orXmu3zoN",
        "colab_type": "text"
      },
      "source": [
        "Le DataFrame des produits ne contient aucune donnée manquante. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma8KEfPb3zoO",
        "colab_type": "text"
      },
      "source": [
        "### 3.3. Analyse des valeurs dupliquées"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-jW7YJ33zoQ",
        "colab_type": "text"
      },
      "source": [
        "Ensuite, on s'intéresse au valeur dupliquée. On crée une variable qui va contenir les valeurs dupliquées dans notre table pour pouvoir les isoler et voir la forme de ces valeurs dupliquées."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9xIpFcI3zoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duplicated = prod.duplicated()\n",
        "prod[duplicated]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr1-1KKU3zoW",
        "colab_type": "text"
      },
      "source": [
        "Le DataFrame prod ne présente pas de valeur dupliqué. On peut donc le laisser ainsi. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viTkjAdK3zoW",
        "colab_type": "text"
      },
      "source": [
        "### 3.4. Suppression du produit T_0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRuscKBi3zoW",
        "colab_type": "text"
      },
      "source": [
        "En effectuant le nettoyage du fichier des transactions, on a observé la présence d'un produit dont la valeur était T_0. Sachant que les données associées aux sessions test ont été supprimé dans le fichier des transactions, il peut être intéressant de supprimer ce produit T_0 pour ne pas fausser les analyses qui suivront. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubCkWtLW3zoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_0 = prod.loc[prod['id_prod'] == 'T_0']\n",
        "print(t_0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSH8DgAz3zoc",
        "colab_type": "text"
      },
      "source": [
        "Maintenant que l'on a identifié ce produit T_0, on va pouvoir le supprimer du fichier en utilisant la méthode .drop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66US1lpf3zod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prod.drop(731, 0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RyAVyfz3zog",
        "colab_type": "text"
      },
      "source": [
        "On vérifie que la donnée a été supprimé du fichier des produits. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OALOM_nz3zoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_0 = prod.loc[prod['id_prod'] == 'T_0']\n",
        "print(t_0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4MpSEqA3zol",
        "colab_type": "text"
      },
      "source": [
        "## 4. Nettoyage des données des clients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxUJhoAf3zom",
        "colab_type": "text"
      },
      "source": [
        "Concernant le fichier client, la méthode sera la même que pour les produits. On commence d'abord par afficher les premières lignes du DataFrame ainsi que les types pour voir la composition de celui-ci. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a77zYwla3zom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(custom.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3vSTi393zop",
        "colab_type": "text"
      },
      "source": [
        "Ce Dataframe est lui aussi composé de trois colonnes contenant les identifiants des clients, le sexe et l'année de naissance des clients. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXBvz2Rh3zoq",
        "colab_type": "text"
      },
      "source": [
        "### 4.1. Analyse des types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUVOFs2u3zor",
        "colab_type": "text"
      },
      "source": [
        "On s'intéresse ensuite aux types des données présents dans le fichier client."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxeQ_6eD3zor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(custom.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqe5ETWW3zou",
        "colab_type": "text"
      },
      "source": [
        "La variable 'sex' apparaît comme un objet, il peut être plus intéressant de changer ce type en variable catégorielle. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK2Sk5SO3zov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom['sex'] = custom['sex'].astype('category')\n",
        "custom.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg1rUzAc3zoy",
        "colab_type": "text"
      },
      "source": [
        "### 4.2. Analyse des données manquantes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkI53jxo3zoz",
        "colab_type": "text"
      },
      "source": [
        "On cherche la présence de valeurs manquantes (NaN) dans le fichier client. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTRG4_6U3zoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom.isna().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xigPki203zo4",
        "colab_type": "text"
      },
      "source": [
        "Le fichier client ne présente pas de données manquantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHRJiMpA3zo5",
        "colab_type": "text"
      },
      "source": [
        "### 4.3. Analyse des données dupliquées"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hzy55DmO3zo6",
        "colab_type": "text"
      },
      "source": [
        "On regarde la présence de données dupliquées et on les stocke dans une variable que l'on nomme duplicated_custom."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I3pmfa43zo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duplicated_custom = custom.duplicated()\n",
        "custom[duplicated_custom]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PelBYsa3zo-",
        "colab_type": "text"
      },
      "source": [
        "Ce DataFrame ne contient pas de données dupliquées. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D5NdEdr3zo_",
        "colab_type": "text"
      },
      "source": [
        "### 4.4. Suppresion des clients ct_0 et ct_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUuPgvOO3zo_",
        "colab_type": "text"
      },
      "source": [
        "Lors du nettoyage du fichier des transactions, on avait vu apparaître des clients associés à des sessions de test. Ces clients possédaient les identifiants ct_0 et ct_1. On va donc supprimer ces deux clients pour ne pas fausser les analyses qui suivront."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt-CKYew3zo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ct_0 = custom.loc[custom['client_id'] == 'ct_0']\n",
        "ct_1 = custom.loc[custom['client_id'] == 'ct_1']\n",
        "print(ct_0)\n",
        "print(ct_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJaD37YZ3zpC",
        "colab_type": "text"
      },
      "source": [
        "On supprime ces deux valeurs en utilisant la méthode .drop(). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6ZrLetB3zpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom.drop([2735, 8494], 0, inplace=True)\n",
        "custom.sort_values('client_id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtVLjUii3zpO",
        "colab_type": "text"
      },
      "source": [
        "## 5. Analyse et croisement avec les autres DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZM8IDYIz3zpO",
        "colab_type": "text"
      },
      "source": [
        "On cherche ensuite si des id_prod sont présents dans les ventes mais pas dans le fichier produit. Si c'est le cas, on supprime ce produit car il ne possède pas de prix. On fait de même avec les client_id. POur cela, on crée deux colonnes contenant des booléans permettant de vérifier la présence de ces anomalies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7nM-a5K3zpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sells['id_prod_prod'] = sells['id_prod'].isin(prod['id_prod'])\n",
        "sells['client_id_custom'] = sells['client_id'].isin(custom['client_id'])\n",
        "print(sells.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwXS_-t93zpS",
        "colab_type": "text"
      },
      "source": [
        "On affiche les produits pour lesquels la variable id_prod_prod vaut False. Cela signifie que ce code produit se trouve uniquement dans les ventes mais pas dans les produits. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Nt56QMD3zpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id_prod_false = sells[sells['id_prod_prod'] == False]\n",
        "id_prod_false = id_prod_false.groupby('id_prod').mean()\n",
        "print(id_prod_false)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ3HY9ep3zpW",
        "colab_type": "text"
      },
      "source": [
        "On remarque que cela concerne uniquement un produit avec l'identifiant '0_2245'.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgZw4m5I3zpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prod_0_2245 = prod.loc[prod['id_prod'] == '0_2245']\n",
        "print(prod_0_2245)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM0z690j3zpa",
        "colab_type": "text"
      },
      "source": [
        "Après vérification dans le DataFrame des produits, il n'existe pas de produit avec cet identifiant. On peut donc essayer d'imputer la valeur de ce produit en lui donnant la moyenne des prix de sa catégorie. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxeU10qI3zpa",
        "colab_type": "text"
      },
      "source": [
        "On répète les étapes précédentes pour repérer la présence de client existants dans les sessions de vente mais qui ne sont pas existants dans le fichier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuynefBs3zpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id_client_false = sells[sells['client_id_custom'] == False]\n",
        "id_client_false = id_client_false.groupby('client_id_custom').mean()\n",
        "print(id_client_false)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU_z-6b03zpd",
        "colab_type": "text"
      },
      "source": [
        "Il n'y a pas de valeur 'False', on ne supprime pas de ligne pour cette condition. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYelL_7u3zpe",
        "colab_type": "text"
      },
      "source": [
        "On calcule donc la moyenne des prix des produits de catégorie. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1OeRsFt3zpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transactions = pd.merge(sells, prod, on=['id_prod']) \n",
        "transactions = pd.pivot_table(index='id_prod', columns='categ', values='price', aggfunc=np.mean, data=transactions)\n",
        "moy_cat0 = transactions[0].mean(skipna=True)\n",
        "print('Prix moyen dans la catégorie 0:', moy_cat0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQPTrQuk3zpi",
        "colab_type": "text"
      },
      "source": [
        "On ajoute donc une nouvelle ligne au fichier des produits pour y ajouter le produit 0_2245 avec un prix de 11.71.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxHtgK7c3zpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prod = prod.sort_index()\n",
        "print(prod.tail())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NuXPV0X3zpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prod.loc[3287] = {'id_prod' : '0_2245', 'price' : 11.71, 'categ' : 0}\n",
        "print(prod.tail())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN77ZX1P3zpo",
        "colab_type": "text"
      },
      "source": [
        "Les ventes associées à ce produit ont bien été ajoutés à ce fichier. On va pouvoir l'importer de cette manière pour pouvoir faire l'analyse des ventes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtMLBEkU3zpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sells = sells.drop(columns=['client_id_custom', 'id_prod_prod'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juAFkGIt359v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.merge(sells, custom, on='client_id')\n",
        "df = pd.merge(df, prod, on = 'id_prod')\n",
        "df['count'] = 1\n",
        "df = df.groupby('client_id').sum().reset_index()\n",
        "df = df.sort_values('count', ascending=False)\n",
        "df = df_custom[['client_id', 'count']]\n",
        "df = pd.merge(df, custom, on='client_id')\n",
        "df = df.sort_values('count', ascending=False)\n",
        "top_10 = df.iloc[0:10]\n",
        "print(top_10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bmuuU1-75an",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask = df.loc[(df['client_id'] == 'c_1609') | (df['client_id'] =='c_6714') | (df['client_id'] =='c_3454') | (df['client_id'] =='c_4958')]\n",
        "outliers = mask.index.tolist()\n",
        "sells = sells.drop(outliers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yLiP8sa3zpr",
        "colab_type": "text"
      },
      "source": [
        "Une fois les corrections faites, on enregistre le fichier pour l'étape de l'analyse. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfhN5neR3zps",
        "colab_type": "text"
      },
      "source": [
        "## 6. Enregistrements des fichiers nettoyés"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IbSG2ie3zpt",
        "colab_type": "text"
      },
      "source": [
        "Une fois le nettoyage des fichiers terminés, on les enregistre pour pouvoir avoir accès aux fichiers d'origine si on remarque un problème lors de l'analyse. Les fichiers source sont conservés dans un dossier 'source' qui se retrouven dans le chemin d'appel du début de ce script. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyZumsiC3zpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sells.to_csv('sells.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7Ba2cG-3zpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prod.to_csv('prod.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldhhDLH53zp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom.to_csv('custom.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF3zf5--3zp4",
        "colab_type": "text"
      },
      "source": [
        "## 7. Analyses complémentaires concernant le mois d'octobre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is4Vb5Cw3zp4",
        "colab_type": "text"
      },
      "source": [
        "Après une analyse du chiffre d'affaire, on observe une anomalie pour le mois d'octobre. On va donc se pencher sur les ventes du mois d'octobre pour pouvoir expliquer cette anomalie. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN4ZGC983zp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sells = sells.reset_index()\n",
        "sells_2 = pd.merge(sells, prod, on = ['id_prod'])\n",
        "sells_2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qwOWas-3zp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sells_2['mois-année'] = pd.to_datetime(sells_2['date'])\n",
        "sells_2['mois-année'] = sells_2['date'].apply(lambda x: x.strftime(\"%b %Y\"))\n",
        "sells_2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awComeht3zqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sells_sept_oct_nov = sells_2[(sells_2['mois-année'] == 'Sep 2021') |(sells_2['mois-année'] == 'Oct 2021') | (sells_2['mois-année'] == 'Nov 2021')]\n",
        "\n",
        "sns.set_style('ticks')\n",
        "sns.set_context('talk')\n",
        "sns.set_palette('Set1')\n",
        "\n",
        "_ = sns.catplot('mois-année', data=sells_sept_oct_nov, hue='categ', kind='count', height=10)\n",
        "_ = plt.xticks(rotation=45)\n",
        "_ = plt.xlabel('Categorie')\n",
        "_ = plt.ylabel('Nombre de ventes')\n",
        "_ = plt.title('Nombre de ventes en fonction du mois')\n",
        "\n",
        "_ = plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcmIfxvT3zqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('mode.chained_assignment', None)\n",
        "sells_oct = sells_2[sells_2['mois-année'] == 'Oct 2021']\n",
        "sells_oct['date'] = sells_oct['date'].apply(lambda x: x.strftime(\"%a %d %b %Y\"))\n",
        "sells_oct['date'] = pd.to_datetime(sells_oct['date'])\n",
        "sells_oct = sells_oct.sort_values('date')\n",
        "sells_oct['date'] = sells_oct['date'].apply(lambda x: x.strftime(\"%a %d %b %Y\"))\n",
        "print(sells_oct)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcZCfXI63zqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set_style('ticks')\n",
        "sns.set_context('talk')\n",
        "sns.set_palette('Set1')\n",
        "\n",
        "_ = sns.catplot('date', data=sells_oct, hue='categ', kind='count', height=10)\n",
        "_ = plt.xticks(rotation=90)\n",
        "_ = plt.xlabel('Date')\n",
        "_ = plt.ylabel('Nombre de ventes')\n",
        "_ = plt.title('Nombre de ventes en fonction de la catégorie pour le mois d\\'octobre 2021')\n",
        "\n",
        "_ = plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}